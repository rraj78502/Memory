{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.9</td>\n",
       "      <td>73.4</td>\n",
       "      <td>55.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.8</td>\n",
       "      <td>66.4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.8</td>\n",
       "      <td>66.0</td>\n",
       "      <td>55.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.7</td>\n",
       "      <td>64.3</td>\n",
       "      <td>52.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.0</td>\n",
       "      <td>71.4</td>\n",
       "      <td>60.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.0</td>\n",
       "      <td>85.3</td>\n",
       "      <td>81.4</td>\n",
       "      <td>112.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.3</td>\n",
       "      <td>82.9</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32.3</td>\n",
       "      <td>75.3</td>\n",
       "      <td>63.1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34.6</td>\n",
       "      <td>53.3</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30.2</td>\n",
       "      <td>86.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33.6</td>\n",
       "      <td>83.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30.9</td>\n",
       "      <td>88.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>35.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30.7</td>\n",
       "      <td>90.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>31.5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30.3</td>\n",
       "      <td>77.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.9</td>\n",
       "      <td>80.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31.3</td>\n",
       "      <td>71.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>31.1</td>\n",
       "      <td>82.3</td>\n",
       "      <td>60.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.1</td>\n",
       "      <td>93.6</td>\n",
       "      <td>58.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>32.9</td>\n",
       "      <td>95.9</td>\n",
       "      <td>55.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>32.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>30.4</td>\n",
       "      <td>87.1</td>\n",
       "      <td>65.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>30.5</td>\n",
       "      <td>84.1</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>30.1</td>\n",
       "      <td>82.3</td>\n",
       "      <td>47.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>31.5</td>\n",
       "      <td>90.7</td>\n",
       "      <td>76.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>33.5</td>\n",
       "      <td>88.4</td>\n",
       "      <td>70.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>33.6</td>\n",
       "      <td>85.9</td>\n",
       "      <td>65.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>31.5</td>\n",
       "      <td>83.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>34.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>52.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>34.9</td>\n",
       "      <td>71.9</td>\n",
       "      <td>49.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>35.6</td>\n",
       "      <td>64.4</td>\n",
       "      <td>45.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>33.8</td>\n",
       "      <td>88.3</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>31.3</td>\n",
       "      <td>92.7</td>\n",
       "      <td>77.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>31.5</td>\n",
       "      <td>91.6</td>\n",
       "      <td>78.6</td>\n",
       "      <td>73.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>32.8</td>\n",
       "      <td>89.7</td>\n",
       "      <td>67.9</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>32.1</td>\n",
       "      <td>89.6</td>\n",
       "      <td>72.6</td>\n",
       "      <td>40.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>29.4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>79.1</td>\n",
       "      <td>89.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>32.2</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>31.5</td>\n",
       "      <td>88.6</td>\n",
       "      <td>62.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>31.3</td>\n",
       "      <td>81.7</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>30.8</td>\n",
       "      <td>89.0</td>\n",
       "      <td>56.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>30.9</td>\n",
       "      <td>94.9</td>\n",
       "      <td>59.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>31.0</td>\n",
       "      <td>85.9</td>\n",
       "      <td>49.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>28.3</td>\n",
       "      <td>92.6</td>\n",
       "      <td>69.4</td>\n",
       "      <td>119.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>28.2</td>\n",
       "      <td>95.3</td>\n",
       "      <td>58.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>27.1</td>\n",
       "      <td>92.9</td>\n",
       "      <td>70.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2      3  4\n",
       "0    37.9  73.4  55.3    0.0  1\n",
       "1    35.8  66.4  55.4    0.0  1\n",
       "2    36.8  66.0  55.4   18.6  1\n",
       "3    36.7  64.3  52.7    0.0  1\n",
       "4    36.2  73.0  52.4    0.0  1\n",
       "5    37.0  71.4  60.4    8.2  1\n",
       "6    29.0  85.3  81.4  112.4  1\n",
       "7    32.3  82.9  74.0    0.0  1\n",
       "8    32.3  75.3  63.1   58.2  1\n",
       "9    34.5  58.0  36.7    0.0  1\n",
       "10   34.6  53.3  37.7    0.0  1\n",
       "11   33.5  71.0  38.1    0.0  1\n",
       "12   28.5  91.0  80.0  185.0  1\n",
       "13   29.0  88.0  70.0   38.3  0\n",
       "14   30.8  87.0  62.0   13.3  1\n",
       "15   30.2  86.0  59.0   11.0  1\n",
       "16   33.6  83.0  51.0    0.0  1\n",
       "17   31.6  93.0  67.0   62.0  1\n",
       "18   30.7  90.0  70.0   49.3  1\n",
       "19   30.5  91.0  70.0   37.7  1\n",
       "20   30.9  88.0  55.0    0.7  1\n",
       "21   34.1  84.0  38.0    5.4  1\n",
       "22   35.0  74.0  36.0    0.0  1\n",
       "23   27.7  96.0  64.0   64.5  1\n",
       "24   30.7  90.0  41.0    0.5  1\n",
       "25   31.5  83.0  24.0    0.0  1\n",
       "26   30.3  77.0  23.0    0.0  1\n",
       "27   30.9  80.0  23.0    0.0  1\n",
       "28   31.3  71.0  19.0    0.0  1\n",
       "29   30.3  73.0  29.0    0.0  1\n",
       "..    ...   ...   ...    ... ..\n",
       "395  32.0  88.9  57.4    0.0  1\n",
       "396  31.1  82.3  60.1    0.0  1\n",
       "397  31.1  93.6  58.4    0.0  1\n",
       "398  32.9  95.9  55.7    0.0  1\n",
       "399  32.0  83.3  56.5    0.0  1\n",
       "400  30.4  87.1  65.3    0.0  1\n",
       "401  30.5  84.1  55.6    0.0  0\n",
       "402  30.1  82.3  47.6    0.0  0\n",
       "403  31.5  90.7  76.7   54.6  1\n",
       "404  33.5  88.4  70.1   26.0  0\n",
       "405  33.6  85.9  65.4   10.0  1\n",
       "406  31.5  83.7  71.4   11.1  1\n",
       "407  34.0  70.3  52.3    0.6  1\n",
       "408  34.9  71.9  49.3    8.0  1\n",
       "409  35.6  64.4  45.6    1.3  0\n",
       "410  33.8  88.3  64.0   50.9  1\n",
       "411  31.3  92.7  77.3   81.8  1\n",
       "412  31.5  91.6  78.6   73.7  1\n",
       "413  32.8  89.7  67.9   21.1  1\n",
       "414  32.1  89.6  72.6   40.3  1\n",
       "415  29.4  95.1  79.1   89.2  1\n",
       "416  32.2  93.0  67.6   37.9  1\n",
       "417  31.5  88.6  62.6    0.0  1\n",
       "418  31.3  81.7  65.0    0.0  1\n",
       "419  30.8  89.0  56.6    0.0  1\n",
       "420  30.9  94.9  59.7    0.0  1\n",
       "421  31.0  85.9  49.7    0.0  1\n",
       "422  28.3  92.6  69.4  119.7  1\n",
       "423  28.2  95.3  58.7    0.0  1\n",
       "424  27.1  92.9  70.6   11.7  1\n",
       "\n",
       "[425 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_table(\"data.csv\", sep=',', header=None)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 37.9  73.4  55.3]\n",
      " [ 35.8  66.4  55.4]\n",
      " [ 36.8  66.   55.4]\n",
      " ..., \n",
      " [ 28.3  92.6  69.4]\n",
      " [ 28.2  95.3  58.7]\n",
      " [ 27.1  92.9  70.6]] [[  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.86000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  8.20000000e+00]\n",
      " [  1.12400000e+02]\n",
      " [  0.00000000e+00]\n",
      " [  5.82000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.85000000e+02]\n",
      " [  3.83000000e+01]\n",
      " [  1.33000000e+01]\n",
      " [  1.10000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  6.20000000e+01]\n",
      " [  4.93000000e+01]\n",
      " [  3.77000000e+01]\n",
      " [  7.00000000e-01]\n",
      " [  5.40000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  6.45000000e+01]\n",
      " [  5.00000000e-01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  3.95000000e+01]\n",
      " [  5.82000000e+01]\n",
      " [  8.33000000e+01]\n",
      " [  2.31900000e+02]\n",
      " [  1.59000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  5.80000000e+00]\n",
      " [  5.79000000e+01]\n",
      " [  1.45600000e+02]\n",
      " [  3.89000000e+01]\n",
      " [  1.75000000e+01]\n",
      " [  5.65000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  2.80000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  2.00000000e-01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.05000000e+01]\n",
      " [  9.40000000e+01]\n",
      " [  5.15000000e+01]\n",
      " [  4.90000000e+01]\n",
      " [  2.20000000e+00]\n",
      " [  2.23000000e+01]\n",
      " [  5.41000000e+01]\n",
      " [  7.63000000e+01]\n",
      " [  4.00000000e-01]\n",
      " [  2.53000000e+01]\n",
      " [  2.87000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  2.17000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  5.52000000e+01]\n",
      " [  2.76000000e+01]\n",
      " [  6.26000000e+01]\n",
      " [  3.30000000e+00]\n",
      " [  1.36000000e+01]\n",
      " [  1.19000000e+01]\n",
      " [  6.14000000e+01]\n",
      " [  8.77000000e+01]\n",
      " [  2.51000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.80000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  5.00000000e+00]\n",
      " [  5.00000000e-01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  3.00000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  4.20000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  6.57000000e+01]\n",
      " [  2.90000000e+00]\n",
      " [  3.02000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  2.10000000e+00]\n",
      " [  6.80000000e+00]\n",
      " [  6.78000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  5.00000000e+00]\n",
      " [  9.78000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  7.00000000e-01]\n",
      " [  1.40000000e+01]\n",
      " [  7.60000000e+00]\n",
      " [  7.00000000e+00]\n",
      " [  2.02000000e+01]\n",
      " [  7.60000000e+01]\n",
      " [  3.20000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  1.03000000e+01]\n",
      " [  6.16000000e+01]\n",
      " [  7.98000000e+01]\n",
      " [  3.58000000e+01]\n",
      " [  2.94000000e+01]\n",
      " [  1.40000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  3.77000000e+01]\n",
      " [  5.82000000e+01]\n",
      " [  2.53000000e+01]\n",
      " [  5.70000000e+00]\n",
      " [  1.15000000e+01]\n",
      " [  5.05000000e+01]\n",
      " [  7.00000000e-01]\n",
      " [  6.74000000e+01]\n",
      " [  8.48000000e+01]\n",
      " [  8.82000000e+01]\n",
      " [  1.12000000e+01]\n",
      " [  3.66000000e+01]\n",
      " [  1.00000000e+00]\n",
      " [  2.10000000e+00]\n",
      " [  8.50000000e+00]\n",
      " [  1.50000000e+01]\n",
      " [  6.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  3.64000000e+01]\n",
      " [  4.73000000e+01]\n",
      " [  5.50000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  6.57000000e+01]\n",
      " [  2.00000000e+01]\n",
      " [  1.19800000e+02]\n",
      " [  6.38000000e+01]\n",
      " [  2.20000000e+01]\n",
      " [  1.24000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  4.82000000e+01]\n",
      " [  8.69000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  4.18000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.43000000e+01]\n",
      " [  2.52000000e+01]\n",
      " [  2.00000000e-01]\n",
      " [  3.69000000e+01]\n",
      " [  2.22000000e+01]\n",
      " [  2.00000000e+00]\n",
      " [  9.60000000e+00]\n",
      " [  5.26000000e+01]\n",
      " [  7.38000000e+01]\n",
      " [  9.90000000e+01]\n",
      " [  1.10000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.40000000e+00]\n",
      " [  8.03000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  3.80000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  6.30000000e+00]\n",
      " [  2.10000000e+01]\n",
      " [  6.70000000e+00]\n",
      " [  2.13000000e+01]\n",
      " [  2.50000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  7.68000000e+01]\n",
      " [  9.10000000e+00]\n",
      " [  4.60000000e+00]\n",
      " [  2.70000000e+01]\n",
      " [  5.40000000e+00]\n",
      " [  4.32000000e+01]\n",
      " [  1.47200000e+02]\n",
      " [  2.44000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  5.64000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  2.00000000e-01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  2.68000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  5.00000000e+00]\n",
      " [  6.80000000e+00]\n",
      " [  3.40000000e+01]\n",
      " [  9.62000000e+01]\n",
      " [  2.22000000e+01]\n",
      " [  1.40000000e+00]\n",
      " [  4.52000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  4.00000000e+00]\n",
      " [  1.14000000e+02]\n",
      " [  8.16000000e+01]\n",
      " [  3.24000000e+01]\n",
      " [  5.66000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  1.34000000e+01]\n",
      " [  1.06000000e+01]\n",
      " [  2.38000000e+01]\n",
      " [  9.40000000e+00]\n",
      " [  1.47600000e+02]\n",
      " [  1.55800000e+02]\n",
      " [  9.20000000e+00]\n",
      " [  1.20000000e+00]\n",
      " [  1.04000000e+01]\n",
      " [  1.06000000e+01]\n",
      " [  1.23200000e+02]\n",
      " [  1.78400000e+02]\n",
      " [  1.47200000e+02]\n",
      " [  6.80000000e+00]\n",
      " [  2.00000000e+01]\n",
      " [  1.16000000e+01]\n",
      " [  4.40000000e+00]\n",
      " [  6.28000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  8.76000000e+01]\n",
      " [  8.00000000e-01]\n",
      " [  0.00000000e+00]\n",
      " [  2.40000000e+00]\n",
      " [  1.80000000e+00]\n",
      " [  3.74000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  4.20000000e+00]\n",
      " [  1.90000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.54000000e+01]\n",
      " [  1.96000000e+01]\n",
      " [  3.00000000e+00]\n",
      " [  1.00000000e+01]\n",
      " [  1.30000000e+01]\n",
      " [  1.21800000e+02]\n",
      " [  6.86000000e+01]\n",
      " [  7.50000000e+01]\n",
      " [  8.60000000e+00]\n",
      " [  1.40000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  5.90000000e+00]\n",
      " [  5.28000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.16000000e+01]\n",
      " [  3.16000000e+01]\n",
      " [  4.36000000e+01]\n",
      " [  2.80000000e+00]\n",
      " [  5.80000000e+01]\n",
      " [  5.06000000e+01]\n",
      " [  1.08000000e+01]\n",
      " [  3.74000000e+01]\n",
      " [  5.91000000e+01]\n",
      " [  3.80000000e+00]\n",
      " [  9.69000000e+01]\n",
      " [  7.20000000e+00]\n",
      " [  3.22000000e+01]\n",
      " [  1.24200000e+02]\n",
      " [  3.57000000e+01]\n",
      " [  1.09300000e+02]\n",
      " [  1.32800000e+02]\n",
      " [  1.90000000e+00]\n",
      " [  8.83000000e+01]\n",
      " [  6.26000000e+01]\n",
      " [  6.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  4.22000000e+01]\n",
      " [  7.74000000e+01]\n",
      " [  2.66000000e+01]\n",
      " [  4.76000000e+01]\n",
      " [  4.40000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  5.54000000e+01]\n",
      " [  4.63000000e+01]\n",
      " [  6.40000000e+00]\n",
      " [  4.30000000e+00]\n",
      " [  4.11000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  2.20000000e+00]\n",
      " [  4.09000000e+01]\n",
      " [  1.03000000e+01]\n",
      " [  4.60000000e+00]\n",
      " [  4.82000000e+01]\n",
      " [  9.18000000e+01]\n",
      " [  3.82000000e+01]\n",
      " [  2.19000000e+01]\n",
      " [  2.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  4.56000000e+01]\n",
      " [  1.91000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  1.40000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  2.75000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  5.05000000e+01]\n",
      " [  1.00000000e+01]\n",
      " [  2.20000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  2.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  3.58000000e+01]\n",
      " [  5.99000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  1.07000000e+02]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  5.46000000e+01]\n",
      " [  2.60000000e+01]\n",
      " [  1.00000000e+01]\n",
      " [  1.11000000e+01]\n",
      " [  6.00000000e-01]\n",
      " [  8.00000000e+00]\n",
      " [  1.30000000e+00]\n",
      " [  5.09000000e+01]\n",
      " [  8.18000000e+01]\n",
      " [  7.37000000e+01]\n",
      " [  2.11000000e+01]\n",
      " [  4.03000000e+01]\n",
      " [  8.92000000e+01]\n",
      " [  3.79000000e+01]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  0.00000000e+00]\n",
      " [  1.19700000e+02]\n",
      " [  0.00000000e+00]\n",
      " [  1.17000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "X = df0[df0.columns[0:3]]\n",
    "X = np.array(X)\n",
    "Y = df0[df0.columns[3:4]]\n",
    "Y = np.array(Y)\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/divyam/machineLearning/projects/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "model = Sequential()\n",
    "#model.add(Dense(units=64, input_dim=(12,)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(units=12))\n",
    "#model.add(Activation('softmax'))\n",
    "model.add(Dense(12, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, input_dim=3, init='uniform', activation='relu'))\n",
    "model.add(Dense(4, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "425/425 [==============================] - 0s - loss: -0.1521 - acc: 0.0024         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cba7f7e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=1, batch_size="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/425 [=>............................] - ETA: 0sAccuracy: 0.24%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print (\"Accuracy: %.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 5.26%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "train_data_X = map(lambda X: [X], list(X[:-20]))\n",
    "train_data_Y = list(Y[:-20])\n",
    "test_data_X = map(lambda X: [X], list(X[-20:]))\n",
    "test_data_Y = list(Y[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-530c68fac28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/divyam/machineLearning/projects/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 512\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/divyam/machineLearning/projects/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/home/divyam/machineLearning/projects/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'map'"
     ]
    }
   ],
   "source": [
    "lm.fit(train_data_X,train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.11759882],\n",
       "       [  1.12986013],\n",
       "       [ 13.86254324],\n",
       "       [ 37.75923644],\n",
       "       [ 34.27163666],\n",
       "       [ 34.96669609],\n",
       "       [ 55.94478795],\n",
       "       [ 42.16338504],\n",
       "       [ 37.29177638],\n",
       "       [ 28.01601914],\n",
       "       [ 17.00874396],\n",
       "       [  1.47736919],\n",
       "       [ -1.86575698],\n",
       "       [ 34.39154635],\n",
       "       [ 12.49690568],\n",
       "       [ -4.17857597],\n",
       "       [  1.14823143],\n",
       "       [  0.67462007],\n",
       "       [  1.14819013],\n",
       "       [  9.37518626]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-f95d2735f83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/divyam/machineLearning/projects/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3434\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3435\u001b[0;31m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3437\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/divyam/machineLearning/projects/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/divyam/machineLearning/projects/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   3956\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3958\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
